{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import (\n",
    "    avg,\n",
    "    col,\n",
    "    count,\n",
    "    sum as Fsum,\n",
    "    to_date,\n",
    "    to_timestamp,\n",
    "    when,\n",
    ")\n",
    "\n",
    "project_id = \"de2025-471807\"\n",
    "bq_dataset = \"netflix\"\n",
    "temp_bucket = \"netflix-group5-temp\"\n",
    "gcs_data_bucket = \"netflix_data_25\"\n",
    "\n",
    "# Spark configuration\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"BigQueryNetflixIngest\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"4g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"2\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "spark.conf.set(\"temporaryGcsBucket\", temp_bucket)\n",
    "spark.conf.set(\"viewsEnabled\", \"true\")\n",
    "\n",
    "# Define the mapping between logical table names and objects in the data bucket\n",
    "table_configs = {\n",
    "    \"users\": \"users.csv\",\n",
    "    \"movies\": \"movies.csv\",\n",
    "    \"watch_history\": \"watch_history.csv\",\n",
    "    \"search_logs\": \"search_logs.csv\",\n",
    "    \"reviews\": \"reviews.csv\",\n",
    "    \"recommendation_logs\": \"recommendation_logs.csv\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_table(table_name: str) -> DataFrame:\n",
    "    \"\"\"Read a CSV from Cloud Storage into a Spark DataFrame.\"\"\"\n",
    "    path = f\"gs://{gcs_data_bucket}/{table_configs[table_name]}\"\n",
    "    return (\n",
    "        spark.read.option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .csv(path)\n",
    "    )\n",
    "\n",
    "\n",
    "def nullify_blanks(df: DataFrame, columns) -> DataFrame:\n",
    "    \"\"\"Convert blank strings in the specified columns to nulls for safe casting.\"\"\"\n",
    "    for c in columns:\n",
    "        df = df.withColumn(c, when(col(c) == \"\", None).otherwise(col(c)))\n",
    "    return df\n",
    "\n",
    "\n",
    "raw_tables = {name: load_table(name) for name in table_configs}\n",
    "\n",
    "for name, df in raw_tables.items():\n",
    "    print(f\"Previewing '{name}' dataset\")\n",
    "    df.show(5, truncate=False)\n",
    "\n",
    "# Clean and cast each dataset to align with BigQuery schemas\n",
    "users_df = (\n",
    "    nullify_blanks(\n",
    "        raw_tables[\"users\"], [\"age\", \"gender\", \"monthly_spend\", \"household_size\"]\n",
    "    )\n",
    "    .dropDuplicates([\"user_id\"])\n",
    "    .withColumn(\"age\", col(\"age\").cast(\"double\"))\n",
    "    .withColumn(\"monthly_spend\", col(\"monthly_spend\").cast(\"double\"))\n",
    "    .withColumn(\"household_size\", col(\"household_size\").cast(\"int\"))\n",
    "    .withColumn(\"is_active\", col(\"is_active\").cast(\"boolean\"))\n",
    "    .withColumn(\n",
    "        \"subscription_start_date\",\n",
    "        to_date(col(\"subscription_start_date\"), \"yyyy-MM-dd\"),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"created_at\",\n",
    "        to_timestamp(col(\"created_at\"), \"yyyy-MM-dd HH:mm:ss.SSSSSS\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "movies_df = (\n",
    "    nullify_blanks(\n",
    "        raw_tables[\"movies\"],\n",
    "        [\n",
    "            \"genre_secondary\",\n",
    "            \"imdb_rating\",\n",
    "            \"production_budget\",\n",
    "            \"box_office_revenue\",\n",
    "            \"number_of_seasons\",\n",
    "            \"number_of_episodes\",\n",
    "        ],\n",
    "    )\n",
    "    .dropDuplicates([\"movie_id\"])\n",
    "    .withColumn(\"release_year\", col(\"release_year\").cast(\"int\"))\n",
    "    .withColumn(\"duration_minutes\", col(\"duration_minutes\").cast(\"double\"))\n",
    "    .withColumn(\"imdb_rating\", col(\"imdb_rating\").cast(\"double\"))\n",
    "    .withColumn(\"production_budget\", col(\"production_budget\").cast(\"double\"))\n",
    "    .withColumn(\"box_office_revenue\", col(\"box_office_revenue\").cast(\"double\"))\n",
    "    .withColumn(\"number_of_seasons\", col(\"number_of_seasons\").cast(\"int\"))\n",
    "    .withColumn(\"number_of_episodes\", col(\"number_of_episodes\").cast(\"int\"))\n",
    "    .withColumn(\"is_netflix_original\", col(\"is_netflix_original\").cast(\"boolean\"))\n",
    "    .withColumn(\"content_warning\", col(\"content_warning\").cast(\"boolean\"))\n",
    "    .withColumn(\"added_to_platform\", to_date(col(\"added_to_platform\"), \"yyyy-MM-dd\"))\n",
    ")\n",
    "\n",
    "watch_history_df = (\n",
    "    nullify_blanks(\n",
    "        raw_tables[\"watch_history\"],\n",
    "        [\"watch_duration_minutes\", \"progress_percentage\", \"user_rating\"],\n",
    "    )\n",
    "    .dropDuplicates([\"session_id\"])\n",
    "    .withColumn(\"watch_date\", to_date(col(\"watch_date\"), \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"watch_duration_minutes\", col(\"watch_duration_minutes\").cast(\"double\"))\n",
    "    .withColumn(\"progress_percentage\", col(\"progress_percentage\").cast(\"double\"))\n",
    "    .withColumn(\"is_download\", col(\"is_download\").cast(\"boolean\"))\n",
    "    .withColumn(\"user_rating\", col(\"user_rating\").cast(\"double\"))\n",
    ")\n",
    "\n",
    "search_logs_df = (\n",
    "    nullify_blanks(raw_tables[\"search_logs\"], [\"clicked_result_position\"])\n",
    "    .dropDuplicates([\"search_id\"])\n",
    "    .withColumn(\"search_date\", to_date(col(\"search_date\"), \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"results_returned\", col(\"results_returned\").cast(\"int\"))\n",
    "    .withColumn(\"clicked_result_position\", col(\"clicked_result_position\").cast(\"int\"))\n",
    "    .withColumn(\"search_duration_seconds\", col(\"search_duration_seconds\").cast(\"double\"))\n",
    "    .withColumn(\"had_typo\", col(\"had_typo\").cast(\"boolean\"))\n",
    "    .withColumn(\"used_filters\", col(\"used_filters\").cast(\"boolean\"))\n",
    ")\n",
    "\n",
    "reviews_df = (\n",
    "    nullify_blanks(raw_tables[\"reviews\"], [\"sentiment_score\", \"review_text\"])\n",
    "    .dropDuplicates([\"review_id\"])\n",
    "    .withColumn(\"review_date\", to_date(col(\"review_date\"), \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"rating\", col(\"rating\").cast(\"int\"))\n",
    "    .withColumn(\"is_verified_watch\", col(\"is_verified_watch\").cast(\"boolean\"))\n",
    "    .withColumn(\"helpful_votes\", col(\"helpful_votes\").cast(\"double\"))\n",
    "    .withColumn(\"total_votes\", col(\"total_votes\").cast(\"double\"))\n",
    "    .withColumn(\"sentiment_score\", col(\"sentiment_score\").cast(\"double\"))\n",
    ")\n",
    "\n",
    "recommendation_logs_df = (\n",
    "    nullify_blanks(raw_tables[\"recommendation_logs\"], [\"recommendation_score\"])\n",
    "    .dropDuplicates([\"recommendation_id\"])\n",
    "    .withColumn(\"recommendation_date\", to_date(col(\"recommendation_date\"), \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"recommendation_score\", col(\"recommendation_score\").cast(\"double\"))\n",
    "    .withColumn(\"was_clicked\", col(\"was_clicked\").cast(\"boolean\"))\n",
    "    .withColumn(\"position_in_list\", col(\"position_in_list\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "cleaned_tables = {\n",
    "    \"users\": users_df,\n",
    "    \"movies\": movies_df,\n",
    "    \"watch_history\": watch_history_df,\n",
    "    \"search_logs\": search_logs_df,\n",
    "    \"reviews\": reviews_df,\n",
    "    \"recommendation_logs\": recommendation_logs_df,\n",
    "}\n",
    "\n",
    "\n",
    "def write_to_bigquery(df: DataFrame, table_name: str, mode: str = \"overwrite\") -> None:\n",
    "    (\n",
    "        df.write.format(\"bigquery\")\n",
    "        .option(\"project\", project_id)\n",
    "        .option(\"dataset\", bq_dataset)\n",
    "        .option(\"table\", table_name)\n",
    "        .mode(mode)\n",
    "        .save()\n",
    "    )\n",
    "\n",
    "\n",
    "for table_name, dataframe in cleaned_tables.items():\n",
    "    print(f\"Writing '{table_name}' to BigQuery dataset {project_id}.{bq_dataset}\")\n",
    "    write_to_bigquery(dataframe, table_name)\n",
    "\n",
    "# Curated analytics tables\n",
    "user_engagement_df = (\n",
    "    watch_history_df.join(\n",
    "        users_df.select(\"user_id\", \"subscription_plan\", \"country\"),\n",
    "        on=\"user_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .groupBy(\"user_id\", \"subscription_plan\", \"country\")\n",
    "    .agg(\n",
    "        Fsum(\"watch_duration_minutes\").alias(\"total_watch_minutes\"),\n",
    "        avg(\"progress_percentage\").alias(\"avg_progress_percentage\"),\n",
    "        Fsum(when(col(\"action\") == \"completed\", 1).otherwise(0)).alias(\n",
    "            \"completed_sessions\"\n",
    "        ),\n",
    "        count(\"*\").alias(\"total_sessions\"),\n",
    "    )\n",
    ")\n",
    "print(\"Writing 'user_engagement_metrics' analytics table\")\n",
    "write_to_bigquery(user_engagement_df, \"user_engagement_metrics\")\n",
    "\n",
    "content_performance_df = (\n",
    "    watch_history_df.groupBy(\"movie_id\")\n",
    "    .agg(\n",
    "        Fsum(\"watch_duration_minutes\").alias(\"total_watch_minutes\"),\n",
    "        avg(\"progress_percentage\").alias(\"avg_progress_percentage\"),\n",
    "        count(\"*\").alias(\"total_sessions\"),\n",
    "        Fsum(when(col(\"action\") == \"completed\", 1).otherwise(0)).alias(\n",
    "            \"completed_sessions\"\n",
    "        ),\n",
    "    )\n",
    "    .join(\n",
    "        movies_df.select(\"movie_id\", \"title\", \"genre_primary\", \"content_type\"),\n",
    "        on=\"movie_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n",
    "print(\"Writing 'content_performance_metrics' analytics table\")\n",
    "write_to_bigquery(content_performance_df, \"content_performance_metrics\")\n",
    "\n",
    "search_interest_df = (\n",
    "    search_logs_df.groupBy(\"search_query\", \"device_type\", \"had_typo\", \"used_filters\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"search_count\"),\n",
    "        avg(\"search_duration_seconds\").alias(\"avg_search_duration\"),\n",
    "        avg(\"clicked_result_position\").alias(\"avg_clicked_position\"),\n",
    "    )\n",
    ")\n",
    "print(\"Writing 'search_interest_metrics' analytics table\")\n",
    "write_to_bigquery(search_interest_df, \"search_interest_metrics\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
